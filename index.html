<!doctype html>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<html>
  <head>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-150283859-1');
    </script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Nicolas Schreuder's personal website</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Nicolas Schreuder</h1>
        <!--<img src="images/pp.png" class="pull-left" style="margin:20px
          20px 20px 20px; height:250px; width:210px; border-radius:5%">-->
        <img src="images/pp2.png" class="pull-left" style="margin:20px
          20px 20px 20px; height:250px; width:210px; border-radius:25%">
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
         <a href="mailto:&#110;&#105;&#099;&#111;&#108;&#097;&#115;&#046;&#115;&#099;&#104;&#114;&#101;&#117;&#100;&#101;&#114;&#064;&#099;&#110;&#114;&#115;&#046;&#102;&#114;"><i class="fa fa-envelope" style="font-size:35px"></i></a>
         &nbsp;&nbsp;&nbsp;&nbsp;
         <a href="https://github.com/NicolasSchreuder"><i class="fa fa-github" style="font-size:40px"></i></a>
         &nbsp;&nbsp;&nbsp;
         <a href="https://scholar.google.com/citations?user=JVKPO3YAAAAJ&hl=fr"><i class="fa fa-google" style="font-size:40px"></i></a>
      </header>

      <section>
        <h2>About me</h2>
        <p>
        I am a <a href="https://www.cnrs.fr/">CNRS</a> research scientist (“chargé de recherche”), based at the <a href="https://siteigm.univ-mlv.fr/">Laboratoire d'Informatique Gaspard-Monge</a>.
        </p>
        <p>
        Before joining CNRS, I was a postdoctoral researcher working with <a href="https://web.mit.edu/lrosasco/www/">Lorenzo Rosasco</a> at <a href="https://unige.it/it/">Università di Genova</a>, Italy.
        </p>
        <p>
        I hold a PhD in Statistics from <a href="http://crest.science/">CREST (Center for Research in Economics and Statistics)</a> and <a href="https://www.ip-paris.fr/">Institut Polytechnique de Paris</a>, where I was supervised by <a href="https://adalalyan.github.io/">Arnak Dalalyan</a> and <a href="https://vebrunel.fr/">Victor-Emmanuel Brunel</a>.
        My PhD dissertation is available <a href="https://tel.archives-ouvertes.fr/tel-03435618">here</a>.
        </p>        

        <p>
        I have primarily worked on fairness in machine learning from a statistical learning perspective. I am interested in designing and analyzing learning algorithms that incorporate key aspects such as fairness, robustness, and privacy. Recently I started working on nonparametric hypothesis testing and, in particular, two-sample testing.
        </p>

        <h2>Preprints</h2>
        <ul> 

        <li> Binh Thuan Tran, NS (2026). <b> Minimax-Optimal Two-Sample Test with Sliced Wasserstein</b>. Accepted at AISTATS 2026.
            [<a href="https://arxiv.org/abs/2510.27498">arXiv:2510.27498</a>]</li>
        <li> Antoine Chatalic, Marco Letizia, NS, Lorenzo Rosasco (2025). <b> A Scalable Nyström-Based Kernel Two-Sample Test with Permutations </b>. Submitted.
        [<a href="https://arxiv.org/abs/2502.13570">arXiv:2502.13570</a>]</li>
        </ul>


        <h2>Publications</h2> 
        <ul>

        <li> Sholom Schechtman, NS (2025). <b> The late-stage training dynamics of (stochastic) subgradient descent on homogeneous neural networks</b>. COLT 2025. [<a href="https://proceedings.mlr.press/v291/schechtman25a.html">PMLR 291:5143-5172</a>]</li>
        <li> Antoine Chatalic, NS, Ernesto De Vito, Lorenzo Rosasco (2025). <b> Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via Leverage Scores Sampling</b>. Journal of Machine Learning Research. [<a href="https://www.jmlr.org/papers/v26/23-1551.html">JMLR:v26:23-155126(101):1−55</a>]</li>
        <li> Ziyad Benomar, Evgenii Chzhen, NS, Vianney Perchet (2024). <b> Addressing bias in online selection with limited budget of comparisons</b>. NeurIPS 2024.
        [<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/154926e0b66e2b2a8c1120852f31a12d-Abstract-Conference.html">DOI:10.52202/079017-0361</a>]</li>
        <li> Solenne Gaucher, NS, Evgenii Chzhen (2023). <b> Fair learning with Wasserstein barycenters for non-decomposable performance measures</b>. AISTATS 2023.
        [<a href="https://proceedings.mlr.press/v206/gaucher23a.html">PMLR 206:2436-2459</a>] </li>
        <li> Evgenii Chzhen, NS (2022). <b> A minimax framework for quantifying risk-fairness trade-off in regression</b>. Annals of Statistics.
        [<a href="https://projecteuclid.org/journals/annals-of-statistics/volume-50/issue-4/A-minimax-framework-for-quantifying-risk-fairness-trade-off-in/10.1214/22-AOS2198.short">10.1214/22-AOS2198</a>] </li>
        <li> Antoine Chatalic, NS, Alessandro Rudi, Lorenzo Rosasco (2022). <b> Nyström Kernel Mean Embeddings</b>. ICML 2022.
        [<a href="https://proceedings.mlr.press/v162/chatalic22a.html">PMLR 162:3006-3024</a>] </li>
        <li> NS (2021). <b> A study of some trade-offs in statistical learning: online learning, generative models and fairness</b>. PhD manuscript. Institut Polytechnique de Paris.
        [<a href="https://tel.archives-ouvertes.fr/tel-03435618/document">tel-03435618</a>] </li>
        <li> NS, Evgenii Chzhen (2021). <b> Classification with abstention but without disparities</b>. UAI 2021. Runner-up for best student paper award.
        [<a href="https://proceedings.mlr.press/v161/schreuder21a.html">PMLR 161:1227-1236</a>] </li>
        <li> NS, Victor-Emmanuel Brunel, Arnak Dalalyan (2021). <b> Statistical guarantees for generative models without domination</b>. ALT 2021.
        [<a href="http://proceedings.mlr.press/v132/schreuder21a">PMLR 132:1051-1071</a>]  </li>
        <li> Evgenii Chzhen, NS (2020). <b> An example of prediction which complies with Demographic Parity and equalizes group-wise risks in the context of regression</b>. NeurIPS 2020 Workshop on Algorithmic Fairness through the Lens of Causality and Interpretability.
        [<a href="https://arxiv.org/abs/2011.07158">arXiv:2011.07158</a>] </li>
        <li> NS (2020). <b> Bounding the expectation of the supremum of empirical processes indexed by Hölder classes</b>. Math. Meth. Stat. 29, 76–86 (2020).
        [<a href="https://link.springer.com/article/10.3103/S1066530720010056#citeas">link</a>] </li>
        <li> NS, Victor-Emmanuel Brunel, Arnak Dalalyan (2019). <b> A nonasymptotic law of iterated logarithm for general M-estimators</b>. AISTATS 2020.
        [<a href="http://proceedings.mlr.press/v108/dalalyan20a">PMLR 108:1331-1341</a>] </li>
        </ul>

        <h2>Education</h2>
        <ul>
          <li> 2018 - 2021: PhD candidate, <a href="http://crest.science/">CREST</a>, <a href="https://www.ensae.fr/en/">ENSAE Paris</a>, <a href="https://www.ip-paris.fr/en/">IPP</a>. </li>
          <li> 2017 - 2018: Master’s in <a href="http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/">Mathematics, Vision, and Learning (MVA)</a>, <a href="https://ens-paris-saclay.fr/en">ENS Paris-Saclay</a>. </li>
          <li> 2015 - 2018: Master’s-level Engineering Degree in Statistics, <a href="https://www.ensae.fr/en/">ENSAE Paris</a>. </li>
          <li> 2012 - 2015: BSc in Applied Mathematics, <a href="https://www.dauphine.fr/en/welcome.html">Université Paris Dauphine-PSL</a>.</li>
        </ul>



        <h2>Teaching </h2>
        <h3>Professeur attaché at PSL (2023-...)</h3>
        <ul>
          <li> Statistical learning, Double Bachelor's degree in AI and Organizational Sciences, Université Paris-Dauphine.
          <li> Deep learning, "Training for Academics" program, PSL.
        </ul>

        <h3> Adjunct professor at IPP (2023-...)</h3>
         <ul>
          <li> Introduction to ML, MScT Data and Economics for Public Policy.
          <li> Fairness in ML, ENSAE Master’s-level Engineering Degree program.
        </ul>


        <h3>Teaching assistant at ENSAE Paris (2019-2021)</h3>
        <ul>
          <li> Theoretical foundations of ML and advanced ML with <a href="https://sites.google.com/site/vianneyperchet/">V. Perchet</a>.
          <li> Measure theory with <a href="https://akorba.github.io/">A. Korba</a>.
          <li> Applied statistics project with <a href="https://julesdepersin.github.io/">J. Depersin</a>.
          <li> Numerical analysis and numerical linear algebra with  <a href="https://www.ljll.math.upmc.fr/kaber/">S. M. Kaber</a>.
        </ul>


        <p style="margin-top:1cm;"><nobr><small>Hosted on GitHub Pages &mdash; Portrait by Sébastien Coube &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></nobr></p>

    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
